{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"The quick brown fox jumps over the lazy dog.\", \"She sells seashells by the seashore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(text)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max([len(seq) for seq in sequences])\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2825ee85640>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(word_index) + 1, embedding_dim, input_length=max_sequence_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(data, np.array([1, 0]), epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02018143 -0.01607579 -0.03544717  0.01289278  0.01231775  0.07027299\n",
      " -0.03130623 -0.09040331  0.06709317 -0.01265952 -0.03273486 -0.08761272\n",
      " -0.09449638  0.08529471  0.08889297  0.02829394 -0.06152492  0.04285855\n",
      " -0.0497993  -0.01640213 -0.0119776   0.08431392  0.05139645 -0.0619236\n",
      "  0.08061772  0.06747168 -0.03168282 -0.0860505   0.00620947 -0.04780575\n",
      " -0.04820564 -0.00474211 -0.00746055 -0.03142239 -0.02761727  0.08160961\n",
      "  0.05193385  0.04356262  0.05340533 -0.08679651  0.02998646  0.09180222\n",
      "  0.0089333   0.09251238 -0.00306405  0.03920081 -0.02885021 -0.0673708\n",
      "  0.00439252  0.04495623  0.00712648  0.05879378  0.08999017 -0.09482009\n",
      "  0.03382562 -0.08035379 -0.05063454  0.04447416 -0.04696385 -0.01156655\n",
      "  0.01325938 -0.07843927  0.0254649  -0.03658897 -0.04186412 -0.00090583\n",
      " -0.082345   -0.0868438   0.07642506  0.03122268 -0.07517829 -0.0172898\n",
      " -0.04641377  0.09392931  0.01233263 -0.01458344 -0.07637877  0.04115511\n",
      " -0.06585613  0.05901258 -0.08600813 -0.07322468  0.02525856 -0.00515654\n",
      "  0.05130102 -0.01568794  0.06875376  0.07322225 -0.06424624 -0.02071162\n",
      "  0.04684037 -0.04852587  0.04783915  0.0870207   0.04192008  0.01906206\n",
      "  0.00590224 -0.06467896 -0.07808258  0.09281004]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.get_weights()[0]\n",
    "vector = word_vectors[word_index['jumps']]\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
